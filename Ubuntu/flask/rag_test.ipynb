{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baking a cake is a delightful process that requires some basic ingredients and a bit of patience. Here's a step-by-step guide on how to bake a cake:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 2 cups all-purpose flour\n",
      "* 1 teaspoon baking powder\n",
      "* 1 teaspoon salt\n",
      "* 1 cup unsalted butter, softened\n",
      "* 1 3/4 cups granulated sugar\n",
      "* 3 large eggs, at room temperature\n",
      "* 2 teaspoons vanilla extract\n",
      "* Optional: nuts, chocolate chips, or fruit for added flavor and texture\n",
      "\n",
      "Instructions:\n",
      "\n",
      "**Preheating the Oven**\n",
      "\n",
      "1. Preheat your oven to the desired temperature (350°F/180°C is a good starting point).\n",
      "2. Make sure you have a rack in the middle of the oven to ensure even baking.\n",
      "\n",
      "**Preparing the Cake Pan**\n",
      "\n",
      "1. Grease two 9-inch (23cm) round cake pans and line the bottoms with parchment paper.\n",
      "2. If using, sprinkle a small amount of flour or cocoa powder into the prepared pans to prevent sticking.\n",
      "\n",
      "**Mixing the Dry Ingredients**\n",
      "\n",
      "1. In a medium-sized bowl, whisk together the flour, baking powder, and salt. Set aside.\n",
      "\n",
      "**Creaming the Butter and Sugar**\n",
      "\n",
      "1. In a large mixing bowl, use an electric mixer (or a whisk and some elbow grease) to cream together the softened butter and granulated sugar until light and fluffy.\n",
      "2. This should take about 2-3 minutes, depending on your mixer's speed and efficiency.\n",
      "\n",
      "**Adding Eggs and Vanilla**\n",
      "\n",
      "1. Beat in each egg one at a time, making sure each is fully incorporated before adding the next.\n",
      "2. Add the vanilla extract and mix until combined.\n",
      "\n",
      "**Combining Wet and Dry Ingredients**\n",
      "\n",
      "1. Gradually pour the dry ingredients into the wet ingredients, alternating with adding a little milk or water as needed (about 1/4 cup).\n",
      "2. Mix until just combined – don't overmix!\n",
      "\n",
      "**Optional Add-ins**\n",
      "\n",
      "1. If using nuts, chocolate chips, or fruit, fold them into the batter at this stage.\n",
      "\n",
      "**Baking the Cake**\n",
      "\n",
      "1. Divide the batter evenly between the prepared pans and smooth out the tops.\n",
      "2. Place the pans in the preheated oven and bake for 25-30 minutes (or until a toothpick inserted comes out clean).\n",
      "3. Rotate the pans halfway through baking to ensure even browning.\n",
      "\n",
      "**Cooling and Assembly**\n",
      "\n",
      "1. Remove the cakes from the oven and let them cool in their pans for 5-10 minutes.\n",
      "2. Transfer the cakes to wire racks to cool completely.\n",
      "3. Once cooled, you can frost and decorate your cake as desired (or enjoy it as is – we won't judge!).\n",
      "\n",
      "**Tips and Variations**\n",
      "\n",
      "* Make sure to not overmix the batter, as this can lead to a dense or tough cake.\n",
      "* Experiment with different flavor combinations by using various extracts (e.g., almond, lemon), spices (e.g., cinnamon, nutmeg), or citrus zest.\n",
      "* If you're new to cake baking, consider starting with a simpler recipe and adjusting ingredients/techniques as needed.\n",
      "\n",
      "And that's it! With these steps, you'll be well on your way to baking a delicious cake. Happy baking!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama3:instruct\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Describe how to bake a cake\"},\n",
    "    \n",
    "\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3:instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"what is 2+ 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is... (drumroll please)... 4!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89283a9dcf8b4767b68d9ab39d2109f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a414e5fe90455787d3c8b930480751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992ce15e307e4c2c9ab5922a6fcc2c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e144c7aefa4a440d8a18e34ab6fa36ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9abf342f4094023b8b9627b48716279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b006a168704d69a90366d9cd1b3dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tab: [2304.07919] Chain of Thought Prompt Tuning in Vision Language Models at https://arxiv.org/abs/2304.07919', 'Tab: 2305.15021v2.pdf at https://arxiv.org/pdf/2305.15021', 'Tab: [2305.15408] Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective at https://arxiv.org/abs/2305.15408', 'Tab: 2405.15071v2.pdf at https://arxiv.org/pdf/2405.15071', 'Tab: 2305.15408v5.pdf at https://arxiv.org/pdf/2305.15408', 'Tab: [2311.09193] The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task at https://arxiv.org/abs/2311.09193', 'Tab: [2309.07915] MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning at https://arxiv.org/abs/2309.07915', 'Tab: [2401.02582] CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs at https://arxiv.org/abs/2401.02582', 'Tab: 2402.12195v1.pdf at https://arxiv.org/pdf/2402.12195', 'Tab: [2402.12058] Scaffolding Coordinates to Promote Vision-Language Coordination in Large Multi-Modal Models at https://arxiv.org/abs/2402.12058', 'Tab: [2403.12488] DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM at https://arxiv.org/abs/2403.12488', 'Tab: 2405.13872v2.pdf at https://arxiv.org/pdf/2405.13872', 'Tab: 2404.09797v1.pdf at https://arxiv.org/pdf/2404.09797', 'Tab: 2403.12488v2.pdf at https://arxiv.org/pdf/2403.12488', 'Tab: 2402.12058v1.pdf at https://arxiv.org/pdf/2402.12058', 'Tab: 2405.16473v1.pdf at https://arxiv.org/pdf/2405.16473', 'Tab: 2402.13577v1.pdf at https://arxiv.org/pdf/2402.13577', 'Tab: 2311.09193v1.pdf at https://arxiv.org/pdf/2311.09193', 'Tab: [2405.18512] Understanding Transformer Reasoning Capabilities via Graph Algorithms at https://arxiv.org/abs/2405.18512', 'Tab: 2403.12801v1.pdf at https://arxiv.org/pdf/2403.12801', 'Tab: 2403.11220v3.pdf at https://arxiv.org/pdf/2403.11220v3', 'Tab: The Hunger Games Sequels Pitch Meeting - YouTube at https://www.youtube.com/watch?v=tIzZ5uRvcFE&ab_channel=ScreenRant', 'Tab: Quantum at https://chatgpt.com/c/7bc4c272-5d91-4717-b5cc-ef61d5adc5bc', 'Tab: openai whisper api pricing - Google Search at https://www.google.com/search?client=ubuntu&channel=fs&q=openai+whisper+api+pricing', 'Tab: Introducing ChatGPT and Whisper APIs | OpenAI at https://openai.com/index/introducing-chatgpt-and-whisper-apis/', 'Tab: API model whisper - Real cost - API - OpenAI Developer Forum at https://community.openai.com/t/api-model-whisper-real-cost/469816/19', 'Tab: ChatGPT at https://chatgpt.com/c/f0ab46f7-d0f0-4a39-8d85-0af28b5e4245', 'Tab: Debugging - Runtime / this-firefox at about:debugging#/runtime/this-firefox', 'Tab: leg extension machine proper form - Google Search at https://www.google.com/search?client=ubuntu&hs=JDp&sca_esv=44a09aed9e2edf4e&channel=fs&q=leg+extension+machine+proper+form&tbm=vid&source=lnms&prmd=ivsnmbt&sa=X&ved=2ahUKEwjm0_-107qGAxURO0QIHZ67BBgQ0pQJegQIFxAB&biw=2488&bih=1299&dpr=1', 'Tab: The RIGHT Way To Use The Leg Extension For Big Quads! (FIX YOUR FORM!) - YouTube at https://www.youtube.com/watch?v=tTbJBUKnWU8&ab_channel=MindPumpTV', 'Tab: How To: Leg Extension (Cybex) - YouTube at https://www.youtube.com/watch?v=YyvSfVjQeL0&ab_channel=ScottHermanFitness', 'Tab: How To Do Leg Extensions With Perfect Technique (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard', 'Tab: 2309.04902v1.pdf at https://arxiv.org/pdf/2309.04902', 'Tab: 2402.03752v1.pdf at https://arxiv.org/pdf/2402.03752', '']\n"
     ]
    }
   ],
   "source": [
    "def load_text_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a text file and returns a list of lines.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): The path to the text file.\n",
    "    \n",
    "    Returns:\n",
    "    list of str: Each element is a line from the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()  # Read all lines in the file\n",
    "        # Strip whitespace and newlines from the end of each line\n",
    "        lines = [line.strip() for line in lines]\n",
    "        return lines\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/media/fsa/SecondaryDisk/MyWork/GPT/NeedleWindow/Ubuntu/flask/tab_titles.txt'\n",
    "lines = load_text_file(file_path)\n",
    "print(lines)  # Print the list of lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "persistent_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chroma = Chroma(client=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_texts(lines, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24dbb0b1-d86a-4b0c-8d93-64e9e3d363ff']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts(lines[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_texts([\"\"], embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tab: How To Do Leg Extensions With Perfect Technique (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard',\n",
       " 'Tab: 2309.04902v1.pdf at https://arxiv.org/pdf/2309.04902',\n",
       " 'Tab: 2402.03752v1.pdf at https://arxiv.org/pdf/2402.03752',\n",
       " '']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-4:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5ce6d105-3f7a-4d10-a684-7b5085178235',\n",
       " 'dd679892-3d67-460b-b894-c4135a50c492',\n",
       " '2cf7034d-c311-44ed-8d16-7fd5a7ac2fb3',\n",
       " '3b3ae480-3f36-444d-8973-a179640b5c44']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts(lines[-4:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"\"\"   <title>Kintsugi - Fredrik F. Ellertsen</title>\n",
    "<p>Repairing my mug with kintsugi</p>\n",
    "<p>My coffee mug broke earlier this year. Naturally, you wouldn't be reading this if it weren't a\n",
    "                    very special mug: It has accompanied me every day for the last 10 years. Through my\n",
    " </p>\n",
    "<p>The art of Kintsugi (Japanese: 金継ぎ)</p>\n",
    "<p>Kintsugi is the traditional Japanese art of repairing broken pottery. In Kintsugi, one uses natural\n",
    "                    lacquer mixed with various ingredients such as wood powder, polishing compound, </p>\n",
    "<p>Step 1: gluing the pieces together with mugi urushi</p>\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['94c5dfdf-973e-4eb2-b28b-34050d0c167f']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_texts([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prompt = PromptTemplate.from_template(\"\"\"\n",
    "                                        <s>[INST] You are good at matching prompts to corresponding website text fragments. You will receive a query text. You should find out which of the context elements most closely matches it. Return that element. [/INST]</s>\n",
    "                                        [INST] Find this: {input}\n",
    "                                          Context: {context}\n",
    "                                          Answer: \n",
    "                                          [/INST]\n",
    "\n",
    "                                          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity_score_threshold\", \n",
    "                                      search_kwargs={\"k\":5,\n",
    "                                                     \"score_threshold\":0.1,}\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt = \"Leg Workout big quads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, raw_prompt)\n",
    "chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Leg Workout big quads',\n",
       " 'context': [Document(page_content='Tab: How To Do Leg Extensions With Perfect Technique (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard'),\n",
       "  Document(page_content='Tab: 2309.04902v1.pdf at https://arxiv.org/pdf/2309.04902'),\n",
       "  Document(page_content='Tab: 2402.03752v1.pdf at https://arxiv.org/pdf/2402.03752'),\n",
       "  Document(page_content=''),\n",
       "  Document(page_content='')],\n",
       " 'answer': 'Based on the query text \"Leg Workout big quads\", I found that the most closely matching context element is:\\n\\n\"Tab: How To Do Leg Extensions With Perfect Technique  (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard\"\\n\\nThis tab title suggests a video tutorial or article about leg workouts, specifically targeting the quadriceps muscles, which aligns with the query text.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": query_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your desired data structure for text matching.\n",
    "class TextMatch(BaseModel):\n",
    "    #match_found: bool = Field(description=\"Whether an exact match was found\")\n",
    "    title: str = Field(description=\"The html tag title of the text document\")\n",
    "    #matching_concept: str = Field(description=\"The concept found in the document that matched the query\")\n",
    "    #matching_concept_explanation: str = Field(description=\"Explain how it is related to the query\")\n",
    "    #explanation: str = Field(description=\"Explain how it is related to the query\")\n",
    "    #confidence: float = Field(description=\"Confidence score of the match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Leg Workout big quads',\n",
       " 'context': [Document(page_content=''),\n",
       "  Document(page_content=\"   <title>Kintsugi - Fredrik F. Ellertsen</title>\\n<p>Repairing my mug with kintsugi</p>\\n<p>My coffee mug broke earlier this year. Naturally, you wouldn't be reading this if it weren't a\\n                    very special mug: It has accompanied me every day for the last 10 years. Through my\\n </p>\\n<p>The art of Kintsugi (Japanese: 金継ぎ)</p>\\n<p>Kintsugi is the traditional Japanese art of repairing broken pottery. In Kintsugi, one uses natural\\n                    lacquer mixed with various ingredients such as wood powder, polishing compound, </p>\\n<p>Step 1: gluing the pieces together with mugi urushi</p>\\n\\n\\n\")],\n",
       " 'answer': '{\"title\": \"none\"}'}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=TextMatch)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{format_instructions} \\n Please check if the user query is in any of the context items.\" \\\n",
    "         \" If there is an exact matching context item, please return its title html tag contents only.\" \\\n",
    "         \" ONLY GIVE THE TOP MATCH.\"\\\n",
    "         \" ONLY PROVIDE THE JSON OUTPUT.\" \\\n",
    "         \" ANSWER BRIEFLY.\"\n",
    "         \" only reply with the FULL AND COMPLETE <title> </title> of the matched context item IF IT IS A GOOD MATCH. \" \\\n",
    "         \" Return \\\"title\\\" : \\\"none\\\" if there are no incredibly STRONGLY RELEVANT matches.\" \\\n",
    "         \" Context: {context}\" \\\n",
    "         \" \\n\\nQuery: {input}\\n\" \\\n",
    "         ,\n",
    "         \n",
    "    input_variables=[\"context\", \"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "query_prompt = \"Leg Workout big quads\"\n",
    "#query_prompt = \"mug\"\n",
    "\n",
    "response = chain.invoke({\"input\": query_prompt})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Leg Workout big quads',\n",
       " 'context': [Document(page_content=''),\n",
       "  Document(page_content=\"  Title: Kintsugi - Fredrik F. Ellertsen\\n\\nParagraph 1: Repairing my mug with kintsugi\\nParagraph 2: My coffee mug broke earlier this year. Naturally, you wouldn't be reading this if it weren't a\\n                    very special mug: It has accompanied me every day for the last 10 years. Through my\\n \\nParagraph 3: The art of Kintsugi (Japanese: 金継ぎ)\\nParagraph 4: Kintsugi is the traditional Japanese art of repairing broken pottery. In Kintsugi, one uses natural\\n                    lacquer mixed with various ingredients such as wood powder, polishing compound, \\nParagraph 5: Step 1: gluing the pieces together with mugi urushi\\n\\n\")],\n",
       " 'answer': '[{\"text\": \"My coffee mug broke earlier this year.\"}, {\"text\": \"It has accompanied me every day for the last 10 years.\"}, {\"text\": \"Kintsugi is the traditional Japanese art of repairing broken pottery.\"}]'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"text\": \"The RIGHT Way To Use The Leg Extension For Big Quads! (FIX YOUR FORM!) - YouTube at https://www.youtube.com/watch?v=tTbJBUKnWU8&ab_channel=MindPumpTV\"},\\n {\"text\": \"How To Do Leg Extensions With Perfect Technique (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard\"},\\n {\"text\": \"How To: Leg Extension (Cybex) - YouTube at https://www.youtube.com/watch?v=YyvSfVjQeL0&ab_channel=ScottHermanFitness\"}]'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Text: The RIGHT Way To Use The Leg Extension For Big Quads! (FIX YOUR FORM!) - YouTube at https://www.youtube.com/watch?v=tTbJBUKnWU8&ab_channel=MindPumpTV\n",
      "Matched Text: How To Do Leg Extensions With Perfect Technique (Grow Every Quad Head) - YouTube at https://www.youtube.com/watch?v=ljO4jkwv8wQ&ab_channel=JeffNippard\n",
      "Matched Text: How To: Leg Extension (Cybex) - YouTube at https://www.youtube.com/watch?v=YyvSfVjQeL0&ab_channel=ScottHermanFitness\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the JSON output string in 'answer' to a Python dictionary\n",
    "try:\n",
    "    # Parse the JSON content from the 'answer' field\n",
    "    answer_data = json.loads(response['answer'])\n",
    "    # Extract and print the texts or any other relevant data\n",
    "    for match in answer_data:\n",
    "        print(\"Matched Text:\", match['text'])\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error decoding JSON\")\n",
    "except KeyError:\n",
    "    print(\"Key error in accessing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
